#!/usr/bin/env python3
"""
æ‰‹åŠ¨æµ‹è¯•èšåˆé€»è¾‘
"""

import asyncio
import sys
import os
from datetime import datetime, timedelta

# æ·»åŠ workeræ¨¡å—è·¯å¾„
sys.path.append('worker/app')

from database import execute_query_ro, execute_query_agg, get_last_aggregation_time, set_last_aggregation_time

async def test_aggregation():
    """æµ‹è¯•èšåˆé€»è¾‘"""
    print("ğŸ” æ‰‹åŠ¨æµ‹è¯•èšåˆé€»è¾‘")
    print("=" * 50)
    
    try:
        # 1. æ£€æŸ¥æœ€åèšåˆæ—¶é—´
        print("\nğŸ“… 1. æ£€æŸ¥æœ€åèšåˆæ—¶é—´")
        last_time = await get_last_aggregation_time()
        print(f"æœ€åèšåˆæ—¶é—´: {last_time}")
        
        # 2. è®¡ç®—èšåˆæ—¶é—´èŒƒå›´
        print("\nâ° 2. è®¡ç®—èšåˆæ—¶é—´èŒƒå›´")
        current_time = datetime.now()
        end_time = current_time.replace(minute=0, second=0, microsecond=0)
        
        if last_time:
            start_time = datetime.fromisoformat(last_time)
        else:
            start_time = end_time - timedelta(hours=2)
            
        print(f"å¼€å§‹æ—¶é—´: {start_time}")
        print(f"ç»“æŸæ—¶é—´: {end_time}")
        
        # è½¬æ¢ä¸ºæ—¶é—´æˆ³
        start_timestamp = int(start_time.timestamp())
        end_timestamp = int(end_time.timestamp())
        print(f"å¼€å§‹æ—¶é—´æˆ³: {start_timestamp}")
        print(f"ç»“æŸæ—¶é—´æˆ³: {end_timestamp}")
        
        # 3. æ£€æŸ¥åŸå§‹æ•°æ®
        print("\nğŸ“Š 3. æ£€æŸ¥åŸå§‹æ•°æ®")
        check_sql = """
            SELECT COUNT(*) as count
            FROM logs
            WHERE created_at >= %s AND created_at < %s
        """
        results = await execute_query_ro(check_sql, [start_timestamp, end_timestamp])
        print(f"æ—¶é—´èŒƒå›´å†…çš„åŸå§‹è®°å½•æ•°: {results[0]['count'] if results else 0}")
        
        if not results or results[0]['count'] == 0:
            print("âŒ æ²¡æœ‰æ•°æ®å¯èšåˆ")
            return
            
        # 4. æµ‹è¯•å…¨å±€èšåˆSQL
        print("\nğŸ”„ 4. æµ‹è¯•å…¨å±€èšåˆSQL")
        global_sql = """
            SELECT 
                DATE_FORMAT(FROM_UNIXTIME(created_at), '%%Y-%%m-%%d %%H:00:00') AS hour_bucket,
                COUNT(*) AS request_count,
                COALESCE(SUM(prompt_tokens + completion_tokens), 0) AS total_tokens,
                COALESCE(SUM(prompt_tokens), 0) AS prompt_tokens,
                COALESCE(SUM(completion_tokens), 0) AS completion_tokens,
                COALESCE(SUM(quota), 0) AS quota_sum,
                COUNT(DISTINCT user_id) AS unique_users,
                COUNT(DISTINCT token_id) AS unique_tokens
            FROM logs
            WHERE created_at >= %s
              AND created_at < %s
            GROUP BY hour_bucket
            ORDER BY hour_bucket
        """
        
        results = await execute_query_ro(global_sql, [start_timestamp, end_timestamp])
        print(f"èšåˆç»“æœæ•°é‡: {len(results) if results else 0}")
        
        if results:
            print("å‰3æ¡èšåˆç»“æœ:")
            for i, row in enumerate(results[:3]):
                print(f"  {i+1}. {row}")
                
            # 5. æµ‹è¯•æ’å…¥èšåˆæ•°æ®
            print("\nğŸ’¾ 5. æµ‹è¯•æ’å…¥èšåˆæ•°æ®")
            insert_sql = """
                INSERT INTO agg_usage_hourly (
                    hour_bucket, user_id, model_name, channel_id,
                    request_count, total_tokens, prompt_tokens, completion_tokens,
                    quota_sum, unique_users, unique_tokens
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    request_count = VALUES(request_count),
                    total_tokens = VALUES(total_tokens),
                    prompt_tokens = VALUES(prompt_tokens),
                    completion_tokens = VALUES(completion_tokens),
                    quota_sum = VALUES(quota_sum),
                    unique_users = VALUES(unique_users),
                    unique_tokens = VALUES(unique_tokens),
                    updated_at = CURRENT_TIMESTAMP
            """
            
            # æ’å…¥ç¬¬ä¸€æ¡è®°å½•ä½œä¸ºæµ‹è¯•
            test_row = results[0]
            test_data = [
                test_row['hour_bucket'],
                None,  # user_id (å…¨å±€èšåˆ)
                None,  # model_name (å…¨å±€èšåˆ)
                None,  # channel_id (å…¨å±€èšåˆ)
                test_row['request_count'],
                test_row['total_tokens'],
                test_row['prompt_tokens'],
                test_row['completion_tokens'],
                test_row['quota_sum'],
                test_row['unique_users'],
                test_row['unique_tokens']
            ]
            
            affected_rows = await execute_query_agg(insert_sql, test_data)
            print(f"æ’å…¥ç»“æœ: {affected_rows} è¡Œå—å½±å“")
            
            # 6. éªŒè¯æ’å…¥ç»“æœ
            print("\nâœ… 6. éªŒè¯æ’å…¥ç»“æœ")
            verify_sql = "SELECT COUNT(*) as count FROM agg_usage_hourly"
            verify_results = await execute_query_ro(verify_sql, [])
            print(f"èšåˆè¡¨æ€»è®°å½•æ•°: {verify_results[0]['count'] if verify_results else 0}")
            
        else:
            print("âŒ èšåˆæŸ¥è¯¢æ²¡æœ‰è¿”å›ç»“æœ")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_aggregation())
